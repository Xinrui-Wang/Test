{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFkwyba93/DZnwYh9/dBD9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Xinrui-Wang/Test/blob/main/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYk1AwqPWgSJ",
        "outputId": "6274cd22-948e-45cc-c417-81b40b78f5be"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# 加载 .env 文件\n",
        "load_dotenv(\"/content/project.env\")\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key = os.getenv(\"API_KEY\"),\n",
        "    base_url = \"https://api.moonshot.cn/v1\",\n",
        ")\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "    model = \"moonshot-v1-8k\",\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"你是 Kimi，由 Moonshot AI 提供的人工智能助手，你更擅长中文和英文的对话。你会为用户提供安全，有帮助，准确的回答。同时，你会拒绝一切涉及恐怖主义，种族歧视，黄色暴力等问题的回答。Moonshot AI 为专有名词，不可翻译成其他语言。\"},\n",
        "        {\"role\": \"user\", \"content\": \"你好，我叫李雷，1+1等于多少？\"}\n",
        "    ],\n",
        "    temperature = 0.3,\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqC570NPIc_4",
        "outputId": "8906ad1e-5f7d-4f61-f25b-58b8f58bf16a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "你好，李雷！1+1等于2。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key = \"sk-q1zU2DIQ65yIUmKwvDupAPEvgepfgGhiKhaEu5QSa9FHcJ8J\",\n",
        "    base_url = \"https://api.moonshot.cn/v1\",\n",
        ")\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"moonshot-v1-8k\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"你是 Kimi，由 Moonshot AI 提供的人工智能助手，你更擅长中文和英文的对话。你会为用户提供安全，有帮助，准确的回答。同时，你会拒绝一切涉及恐怖主义，种族歧视，黄色暴力等问题的回答。Moonshot AI 为专有名词，不可翻译成其他语言。\",\n",
        "        },\n",
        "        {\"role\": \"user\", \"content\": \"你好，我叫李雷，1+1等于多少？\"},\n",
        "    ],\n",
        "    temperature=0.3,\n",
        "    stream=True,\n",
        ")\n",
        "\n",
        "collected_messages = []\n",
        "for idx, chunk in enumerate(response):\n",
        "    # print(\"Chunk received, value: \", chunk)\n",
        "    chunk_message = chunk.choices[0].delta\n",
        "    if not chunk_message.content:\n",
        "        continue\n",
        "    collected_messages.append(chunk_message)  # save the message\n",
        "    print(f\"#{idx}: {''.join([m.content for m in collected_messages])}\")\n",
        "print(f\"Full conversation received: {''.join([m.content for m in collected_messages])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaBcox1NKAsp",
        "outputId": "d36961f1-20c2-47ef-9374-bc4773450250"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#1: 你好\n",
            "#2: 你好，\n",
            "#3: 你好，李\n",
            "#4: 你好，李雷\n",
            "#5: 你好，李雷！\n",
            "#6: 你好，李雷！1\n",
            "#7: 你好，李雷！1+\n",
            "#8: 你好，李雷！1+1\n",
            "#9: 你好，李雷！1+1等于\n",
            "#10: 你好，李雷！1+1等于2\n",
            "#11: 你好，李雷！1+1等于2。\n",
            "Full conversation received: 你好，李雷！1+1等于2。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key = \"sk-q1zU2DIQ65yIUmKwvDupAPEvgepfgGhiKhaEu5QSa9FHcJ8J\",\n",
        "    base_url = \"https://api.moonshot.cn/v1\",\n",
        ")\n",
        "\n",
        "model_list = client.models.list()\n",
        "model_data = model_list.data\n",
        "\n",
        "for i, model in enumerate(model_data):\n",
        "    print(f\"model[{i}]:\", model.id)"
      ],
      "metadata": {
        "id": "DNlUlldTLH_I",
        "outputId": "c40cb823-3c70-4d87-cbbe-b2599d1d5645",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model[0]: moonshot-v1-8k\n",
            "model[1]: moonshot-v1-32k\n",
            "model[2]: moonshot-v1-128k\n",
            "model[3]: moonshot-v1-auto\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key = 'YOUR_API_KEY'\n",
        "\n",
        "def ask_teacher_role(question):\n",
        "    teacher_prompt = \"\"\"\n",
        "    You are a friendly and knowledgeable English teacher assistant focused on helping students understand and master English language concepts.\n",
        "    Please explain each concept in a simple and easy-to-understand way, providing examples when necessary.\n",
        "    When responding to questions related to grammar, vocabulary, reading comprehension, or speaking, offer clear and accurate explanations with relevant examples to assist in understanding.\n",
        "\n",
        "    If the question is unclear, ask the student to specify their needs. Adjust your language based on the student’s level; use simpler terms if the student is a beginner, or provide a more detailed explanation if they are advanced.\n",
        "    Keep your responses brief but comprehensive, and focus on making the student feel encouraged and motivated in their learning journey.\n",
        "    \"\"\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": teacher_prompt},\n",
        "            {\"role\": \"user\", \"content\": question}\n",
        "        ]\n",
        "    )\n",
        "    return response['choices'][0]['message']['content']\n"
      ],
      "metadata": {
        "id": "macTd8CbVskP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_study_summary(logs):\n",
        "    summary_prompt = \"\"\"\n",
        "    You are a study summary assistant responsible for analyzing a student’s progress based on their learning history and answer logs.\n",
        "    Generate a brief and structured study report that includes:\n",
        "    1) Highlights of the student’s learning achievements and noticeable improvements.\n",
        "    2) Areas that need further practice, identifying specific challenges or gaps.\n",
        "    3) Personalized recommendations for the next steps, focusing on review and areas to strengthen.\n",
        "\n",
        "    Use encouraging language to help the student see their progress and to provide actionable advice. Make the suggestions targeted and useful for guiding the student in their future studies.\n",
        "    \"\"\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": summary_prompt},\n",
        "            {\"role\": \"user\", \"content\": f\"Here is the student's learning log:\\n{logs}\"}\n",
        "        ]\n",
        "    )\n",
        "    return response['choices'][0]['message']['content']\n"
      ],
      "metadata": {
        "id": "oeqw3g_8Vvp7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}